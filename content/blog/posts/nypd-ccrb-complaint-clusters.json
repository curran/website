{
  "date": "2021-06-11T15:10:17-04:00",
  "type": "words",
  "hidden": true,
  "inprogress": false,
  "dek": "In which various tools and methods are explored for analyzing data that describes a network of complaints against NYPD officers (or any other PD with similar public data)",
  "bodyContent": "# Finding Clusters of NYPD Officers In CCRB Complaint Data\n\n## Why?\n\nComplaints filed against police officers by the public are often the first- and only- warning signs that a cop might be on a course of escalating violence towards the public. \n\nIn cases the deaths of George Floyd and Eric Garner the officers who killed them had a documented history of complaints filed against them by the public. Unfortunately nothing was done to disrupt their pattern of abuse, and both ended in the deaths of members of the public the officers had sworn to protect. \n\n[[toc]]\n\n### George Floyd\n\n> Chauvin, who was fired, has said through his attorney that his handling of Floyd’s arrest was a reasonable use of authorized force. But he was the subject of at least **22 complaints** or internal investigations during his more than 19 years at the department, **only one of which resulted in discipline**. These new interviews show not only that he may have used excessive force in the past, but that he had used startlingly similar techniques.\n<https://www.mprnews.org/story/2021/02/05/that-could-have-been-me-the-people-derek-chauvin-choked-before-george-floyd>\n\nThe officer convicted of murdering George Floyd had at least 22 complaints against him. The officer who put Eric Garner in a chokehold and killed him had [7 complaints](https://www.scribd.com/document/342591738/D-Pantaleo-Alleged-CCRB-File) [filed against him](https://gothamist.com/news/newly-leaked-documents-suggests-cop-who-killed-eric-garner-had-history-of-misconduct). \n\n### Eric Garner\n\n> Before he put Garner in the chokehold, the records show, he had **seven disciplinary complaints and 14 individual allegations** lodged against him. Four of those allegations were substantiated by an independent review board.\n<https://archive.thinkprogress.org/daniel-pantaleo-records-75833e6168f3/>\n\nOf the 14 individual allegations, 5 are for force: \"hit against inanimate object\", \"physical force\", and a single complaint in 2014 that would foreshadow the behavior that would eventually end the Officer's career: \"Force - Chokehold\". \n\nI am documenting my analysis in detail for a few reasons:\n- So that other people who may want to perform similar analysis for other Police Departments can understand and recreate my analysis\n- So that every step is documented, and any mistake [can be easily caught and fixed](https://en.wikipedia.org/wiki/Linus%27s_law) by the infinite supply of people on the internet who are smarter than me\n- To maybe inspire people to use computers to investigate the things in the world that are important to them, and share the tools I use to do that\n\n### Network visualization prior work / inspiration\n\nYou may have seen network analysis like this before. \n\n[Jacob Silver used it to look at the spread of anti-vax material](https://disinformationindex.org/2021/03/anti-vaccine-networks-thrive-on-instagram-despite-recent-policy-shifts/). \n\n[Adi Cohen](https://twitter.com/adico11) has pioneered a method of [combining Gephi with CrowdTangle](https://help.crowdtangle.com/en/articles/4495952-network-mapping-with-gephi-and-crowdtangle) to analyze the network of groups and pages sharing links. \n\n\n\n### Provenance\nThe [NYCLU](https://www.nyclu.org/en/campaigns/nypd-misconduct-database) received this data from the CCRB as a result of a FOIL (Freedom of Information Law) request and released it on [their GitHub page](https://github.com/new-york-civil-liberties-union/NYPD-Misconduct-Complaint-Database-Updated). \n\n## The Dataset\n\n### Differences from data previously released by ProPublica\nProPublica released and covered [similar data](https://www.propublica.org/article/nypd-civilian-complaint-review-board-editors-note) in July of 2020. \n\nThey chose to only publish data for \"active-duty officers who’ve had at least one allegation against them substantiated by the CCRB\". \n\nThe dataset we are working with today contains every complaint and officer, even those with no substantiated allegations. \n\nIt also contains officers who were listed as witnesses on complaints, including complaints found as \"unsubstantiated\" or \"unfounded\" by the CCRB.\n\nThis makes it a \"noisier\" dataset. In our case this can be an advantage since we are looking to visualize the network of officers. \n\nBeing named with another officer on a complaint, even if that complaint is unfounded, is a signal that those officers interacted in a way that was noticed by the public. Being the subject of an unfounded complaint together might even cause officers to form a tighter relationship. Because of that, I will incorporate witness data into our analysis. \n\n### NYPD internal structure as it relates to our data\nThe NYPD is divided into coverage areas within the 5 boroughs known as precincts. When I lived in Brooklyn, I lived in the 81st Precinct which covers Bed-Stuy. \n\nThe NYPD also has a number of units, like the Warrant Squad or Narcotics that span different precincts. An officer might report to a numbered precinct, but their command is Brooklyn Narcotics, and they are interacting with other officers in their unit more than the precinct they work out of. Our data reflects this. \n\n## Analysis\n### Overview exploration / metadata\nThe source dataset is an 81.2MB excel file that I received as `FOIL2021-00167_Dataset.xlsx`. It has 3 tabs. The first has some general notes[^1] about the dataset. \n\nThe first tab has the title of **OfficerAllegationHistory** and has 181,627 entries and 47[^2] columns.\n\nThe second tab has the title of **OfficersInvolvedInComplaints** and has 239,608 entries and 18[^3] columns.\n\n## Analyzing our data with Datasette / SQLite\nOnce we [convert our CSV files](https://pypi.org/project/csvs-to-sqlite/) into SQLite `.db` files we can use [Datasette](https://github.com/simonw/datasette) to get a sense of the data and slice off pieces for further analysis. \n\nThe first thing we might want to look at is the top commands that received complaints since 2010. \n```sqlite\nselect [Officer Command At Incident], count([Officer Command At Incident]) from OfficerAllegationHistory \nwhere [Incident Date] BETWEEN '2010-01-01' AND '2010-12-31'\ngroup by [Officer Command At Incident] order by count([Officer Command At Incident]) DESC LIMIT 10\n```\n- 075 PCT: 320\n- 046 PCT: 251\n- 047 PCT: 226\n- 120 PCT: 199\n- BX IRT\t: 196\n- NARCBBN: 178\n- 073 PCT: 176\n- 077 PCT: 173\n- MN IRT: 171\n- 044 PCT: 168\n\nOr the top 10 commands whose complaints ended in penalties. \n\n```sqlite\nselect [Officer Command At Incident], count([Officer Command At Incident]) from OfficerAllegationHistory \nwhere [Incident Date] BETWEEN '2010-01-01' AND '2021-12-31'AND [CCRB Allegation Disposition] = 'Substantiated (Charges)'\ngroup by [Officer Command At Incident] order by count([Officer Command At Incident]) DESC LIMIT 10\n```\n\n- WARRSEC: 91\n- PBBX\t: 84\n- 081 PCT: 71\n- 079 PCT: 70\n- 075 PCT: 68\n- NARCBBN: 67\n- 046 PCT: 66\n- 034 PCT: 61\n- NARCBBX: 56\n- 044 PCT: 54\n\nAfter using Datasette to get a sense for the shape of our dataset, we can use it to filter out a slice of the data to use to feed into our next tool and begin doing our network analysis.\n\n### Filtering out \"Exonerated\" and \"Unfounded\" complaints\n\nTo get our network closer to a representation of officers who are receiving complaints for misconduct we want to filter out any of the cases in which the officer was **Exonerated** or the CCRB's disposition was that it was **Unfounded**. \n\nSo to get every complaint filed since 2010 that wasn't marked as **exonerated** or **unfounded** we'll write a query like\n\n```sqlite\nselect * from OfficerAllegationHistory \nwhere ([Incident Date] BETWEEN '2010-01-01' AND '2021-12-31') AND ([CCRB Allegation Disposition] IS NOT 'Exonerated'\nAND [CCRB Allegation Disposition] IS NOT 'Unfounded')\n```\n\nWhich gives us a slightly more manageable **65,401** rows. We'll save these results off as a .csv for further analysis. \n\nI had to do some funky stuff[^4] to fix the dates in SQLite, but once I did that, it was easy to filter by the date column.\n\nWe can also export new CSVs for all of the incidents since 2010 for a particular precinct:\n```sqlite\nselect * from OfficerAllegationHistory \nwhere [Incident Date] BETWEEN '2010-01-01' AND '2021-12-31' AND [Officer Command At Incident] = '075 PCT'\n```\n\nThese precinct-specific slices are a bit smaller and more manageable for analysis in Observable.\n\nWe'll also want to export another CSV with ONLY complaints that were substantiated\n\n```sqlite\nselect * from OfficerAllegationHistory\nwhere ([Incident Date] BETWEEN '2010-01-01' AND '2021-12-31') AND ([CCRB Allegation Disposition] IS 'Substantiated (Charges)' OR [CCRB Allegation Disposition] IS 'Substantiated (Command Discipline A)'\nOR [CCRB Allegation Disposition] IS 'Substantiated (Command Discipline B)'\n```\n\n## Analyzing our data with Observable\n\n\n## Analyzing our data with Neo4J\nI first encountered Neo4J when I was working with Ben Popken on an [NBC News analysis of tweets tied to Senate Intelligence-identified Russian Twitter Bots](https://neo4j.com/blog/story-behind-russian-twitter-trolls/) where Neo4J provided analysts who were crucial to understanding the shape of our data. \n\nIt is an incredibly useful tool for generating and analyzing networks, and I was excited to have another dataset that would let me use its considerable power. \n\n### Importing our CSV with Cypher\nTo import our `.csv` into a network of node and relationships in Neo4J, we will use the [Cypher](https://neo4j.com/developer/cypher/) query language, which makes this process really easy and the code is relatively readable and easy to follow. \n\nSpecial thanks to [David Allen](https://twitter.com/mdavidallen) at Neo4J for his guidance in writing queries and designing these relationships. \n\nBasically we take the CSV files we exported from Datasette (when we filtered our Exonerated, Unfounded, and everything before 2010) and go through every row and push it into our network.\n\n#### Creating officer nodes\nFirst we tell Neo4J to use officer.id as a unique constraint (this makes things faster, I think?) and create a node for each officer from one CSV.\n```cypher\nCREATE CONSTRAINT officerIdConstraint ON (officer:Officer) ASSERT officer.id IS UNIQUE\n```\n\nThen I loop through every line of the .csv and create a new Officer node for every new officer I see. I use `MERGE` instead of `CREATE` to make sure I don't duplicate officer nodes. \n\n```cypher\nLOAD CSV WITH HEADERS FROM \"http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv\" AS csvLine\nMERGE (officer:Officer {id: csvLine.`Unique Officer Id`, lastName: csvLine.`Officer Last Name`, firstName: csvLine.`Officer First Name`, OfficersInvolvedInComplaints: true})\nRETURN officer\n```\n\nThis creates **29,915** unique officer nodes. \n\nThen we bind more data into it from our other CSV\n\n```cypher\nLOAD CSV WITH HEADERS FROM \"http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory.csv\" AS csvLine\nMERGE (officer:Officer {id: csvLine.`Unique Officer Id`, lastName: csvLine.`Officer Last Name`, firstName: csvLine.`Officer First Name`, shieldNo: csvLine.`Shield No`, currentRank: csvLine.`Current Rank`, currentCommand: csvLine.`Current Command`, OfficerAllegationHistory: true})\nRETURN officer\n```\n\nNow we have **113,265** unique officer nodes. \n\nAn officer node looks like this:\n\n```json\n{\n  \"identity\": 00001,\n  \"properties\": {\n\t\t\"currentRank\": \"Police Officer\",\n\t\t\"currentCommand\": \"81\",\n\t\t\"lastName\": \"Smith\",\n\t\t\"firstName\": \"John\",\n\t\t\"shieldNo\": \"00001\",\n\t\t\"id\": \"000001\",\n\t\t\"OfficerAllegationHistory\": true\n  }\n}\n```\n\nFinally, we need to add a boolean to denote if an officer has ever had a charge substantiated. We'll use this later to please some lawyers. You'll see. \n\n```cypher\nLOAD CSV WITH HEADERS FROM \"http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-SUBSTANTIATED.csv\" AS csvLine\nMERGE (officer:Officer {id: csvLine.`Unique Officer Id`})\nSET officer.ccrbSubstantiatedBool = \"true\"\nRETURN officer\n```\n\nNow we've marked **4,768** of New York's ~36,000 (13%) finest as having a substantiated complaint in the last 10 years. \n\nLet's NOT do the same thing for OfficersInvolved - because that file contains officers who were merely witnesses to substantiated complaints, and we don't want to accidentally label a witness to a substantiated case.  \n\n### Creating officer labels\n\nNow we need to set labels for our nodes depending on whether they have ever had a complaint substantiated. We don't want to label nodes with names for any officers who may have complaints but have never had any substantiated. I have been told that lawyers think this is a good idea. \n\nFirst we set every officer label to their unique ID\n```cypher\nMATCH (o:Officer)\nSET o.label = o.id\n```\n\nThen we look for officers with substantiated complaints and set their label to their full name. \n\n```cypher\nMATCH (o:Officer {ccrbSubstantiatedBool: \"true\"})\nSET o.label = COALESCE(o.firstName ,\"\") + ' ' + COALESCE(o.lastName ,\"\")\n```\n\nNow we have our officers created, we need to create our incidents.\n\n#### MAYBE, POTENTIALLY\nIn order to include dates in our network, we might need to make a dummy date field for our officers. Only incidents have dates in our source data, but to export our dates to Gephi, all nodes need to have the field. \n\n```cypher\nMATCH (o:Officer )\nSET o.date = \"2021-12-31\"\n```\n\nIdeally this would be the date the officer was hired, but that is extra work for unclear reward, though you could probably do some interesting analysis incorporating seniority or analyzing the network effects of complaint-prone cops working with rookies and potentially influencing their behavior. \n\n#### Creating incident nodes\nWe are going to continue to use our CSV which **filtered out** incidents **before 2010** or that were **unfounded or exonerated**.\n\nFirst we tell Neo4J that we have unique incident IDs\n\n```cypher\nCREATE CONSTRAINT incidentIdConstraint ON (incident:Incident) ASSERT incident.id IS UNIQUE\n```\n\nThen we create an incident for every row we see in OfficerAllegationHistory. We'll make note of the precinct the incident occurred in, what the specific allegation was, and what date the incident occurred. \n\n```cypher\nLOAD CSV WITH HEADERS FROM \"http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv\" AS csvLine\nMERGE (incident:Incident {id: csvLine.`Complaint Id`})\nSET incident.incidentPct = COALESCE(csvLine.`Precinct Of Incident Occurrence`,\"N/A\")\nSET incident.ccrbDisposition = csvLine.`CCRB Allegation Disposition`\nSET incident.allegation = csvLine.`Allegation`\nset incident.date = csvLine.`Incident Date`\nRETURN incident\n```\n\nNow let's do the same for **OfficersInvolvedInComplaints**.\n\n```cypher\nLOAD CSV WITH HEADERS FROM \"http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv\" AS csvLine\nMERGE (incident:Incident {id: csvLine.`Complaint Id`})\nSET incident.ccrbDisposition = csvLine.`Complaint Disposition`\nRETURN incident\n```\n\nNow let's create labels for our incidents, which is going to be the allegation. \n\n```cypher\nMATCH (i:Incident)\nSET i.label = i.allegation\n```\n\nNow that we have our **Incidents** and our **Officers** we need to create our relationships between them.\n\n### Creating relationships between incidents and officers \n\nNow for the fun part. \n\nWe are going to create a new relationship called `INVOLVED_IN`, and officers can be `INVOLVED_IN` one or many incidents. Incidents may have one or many officers that were `INVOLVED_IN` it, either as witness or subject officers. \n\nFirst we create our relationships from **OfficersInvolved**:\n\n```cypher\nLOAD CSV WITH HEADERS FROM \"http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv\" AS csvLine\nMATCH (officer:Officer {id: csvLine.`Unique Officer Id`}) with csvLine, officer\nMATCH (incident:Incident {id: csvLine.`Complaint Id`}) with csvLine, officer, incident\nCREATE (officer)-[:INVOLVED_IN {status: csvLine.`Officer Status`}]->(incident)\n```\nWhich creates **94,323** relationships.\n\nThen from **OfficerAllegationHistory**:\n```cypher\nLOAD CSV WITH HEADERS FROM \"http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv\" AS csvLine\nMATCH (officer:Officer {id: csvLine.`Unique Officer Id`}) with csvLine, officer\nMATCH (incident:Incident {id: csvLine.`Complaint Id`}) with csvLine, officer, incident\nCREATE (officer)-[:INVOLVED_IN {allegation: csvLine.`Allegation`, type: csvLine.`FADO Type`}]->(incident)\n```\nNow we have **159,671** relationships. Sick.\n\nNext we can flatten out our graph a little bit and remove incidents if we want. \n\nWe will create a new type of relationship that only occurs between two officers called `CO_OCCURANCE` - we will only make one of these between each officer, but the weight of that link will be decided by how many complaints those officers appear together on. \n\nSo officers who appear on 3 complaints together have a `CO_OCCURANCE` relationship with a weight of 3. This allows us to do some weighted degree analysis when we are making our layout, deciding how large to make nodes, and when we are detecting communities. \n\n```cypher\nMATCH (o1:Officer)-[:INVOLVED_IN]->(i:Incident)<-[:INVOLVED_IN]-(o2:Officer) WHERE id(o1)<id(o2) with o1, o2, count(i) as weightCount CREATE (o1)-[:CO_OCCURANCE { weight: weightCount }]->(o2)\n```\n\n### Eigenvector analysis on our network \nLet's run a standard centrality analysis algorithm called [\"Eigenvector Centrality\"](https://neo4j.com/docs/graph-data-science/current/algorithms/eigenvector-centrality/)\n\n```\nCALL gds.alpha.eigenvector.write({\n  nodeProjection: 'Officer',\n  relationshipProjection: 'CO_OCCURANCE',\n  relationshipProperties: 'weight',\n  relationshipWeightProperty: 'weight',\n  writeProperty: 'eigenvector'\n})\nYIELD nodes, iterations, dampingFactor, writeProperty\n```\n\nNow every Officer node has an `eigenvector` value that represents its centrality across our entire NYPD-wide network. The larger the value, the more central that node is. \n\nWe're also going to find the [modularity](https://neo4j.com/docs/graph-data-science/current/algorithms/modularity-optimization/) for our network using Neo4J. This will help us color our nodes by their \"community\" as defined by this network. \n\n```cypher\nCALL gds.graph.create.cypher(\n    'nypdwide',\n\t  'MATCH (n:Officer) RETURN id(n) AS id',\n\t\t'MATCH (a:Officer)-[l:CO_OCCURANCE]->(b:Officer) RETURN id(a) AS source, id(b) AS target, l.weight AS weight'\n)\nYIELD graphName, nodeCount, relationshipCount, createMillis;\n```\n\n```cypher\nCALL gds.beta.modularityOptimization.mutate('nypdwide', { relationshipWeightProperty: 'weight', mutateProperty: 'community' })\nYIELD nodes, communityCount, ranIterations, didConverge\n```\n\nThe communities that Gephi detects often mirror real-world precincts. As one might expect, officers appear on complaints with other officers in their precinct because they are working together most often. \n\nI like that the algorithm detects communities that resemble precincts, and it actually gives me confidence that the community detection is working. \n\n## Analyzing our data with Gephi\nNeo4J is cool for processing and analyzing tons of data, but I want to draw thousands of circles and lines now and start untangling the hairball of our network. \n\nI am going to use Gephi, which I have a love-hate relationship with, but is unrivaled when it comes to network visualization. Plus, I already know how to use it.\n\nWe are going to [stream our data from Neo4J to Gephi](https://neo4j.com/labs/apoc/4.1/export/gephi/) in order to leverage Neo4J's power to handle huge amounts of data (way more than Gephi) but still get to use Gephi's layout algorithms and analysis techniques. \n\n### Flattened co-occurance network\nTo get our flattened network, which removed incident nodes:\n```cypher\nMATCH path=(o1:Officer)-[r:CO_OCCURANCE]->(o2:Officer) WITH o1, path limit 100000  with o1, collect(path) as paths call apoc.gephi.add(null,'workspace1', paths, 'weight', ['weight', 'id', 'eigenvector', 'firstName', 'lastName', 'label', 'date', 'currentCommand']) yield nodes, relationships, time return nodes, relationships, time ORDER  BY o1.eigenvector DESC\n```\n\nThis streams 100,000 edges and 25,064 nodes into Gephi. \n\nWe'll run the Force Atlas 2 layout algorithm in Gephi to have the nodes arrange themselves into some sort of sense. \n\n### Precinct-specific networks including incidents\nLet's put it all together and stream all the officers from a single precinct using only incidents since 2010. \n```cypher\nMATCH path=(o1:Officer)-[:INVOLVED_IN]->(i:Incident {incidentPct: \"75\"})<-[:INVOLVED_IN]-(o2:Officer)\nwhere i.date IS NOT NULL and apoc.date.parse(i.date, \"ms\", 'YYYY-mm-dd') > 1262304000000\n WITH o1, path, i limit 100000  with o1, i, collect(path) as paths call apoc.gephi.add(null,'workspace1', paths, 'weight', ['weight', 'id', 'eigenvector', 'firstName', 'lastName', 'date']) yield nodes, relationships, time return nodes, relationships, time ORDER  BY o1.eigenvector DESC\n```\n\n## Visualization\n\n## Potential Next Steps\n### Explorable NYPD-wide network\n### Looking at protest complaints\n### Looking at veterans influencing rookies\n### Looking at the effects of NYPD discipline\n### Officer career-specific visualization\n### Analysis of length/outcomes of CCRB investigations\n### Geographic analysis\n\n## Hire me to do work like this\nI do freelance data exploration and visualization for clients who aren't evil. I'd love to work like this for you, just get in touch at <ejfox@ejfox.com>\n\n\n[^1]: The notes say, basically: these are complaints received in or after the year 2000. Cases that are mediated or were attempted to be mediated are excluded. \n\n[^2]: OfficerAllegationHistory columns:\n\t  1: As Of Date\n\t  2: Allegation Record Identity\n\t  3: Unique Officer Id\n\t  4: Active Per Last Reported Status\n\t  5: Last Reported Active Date\n\t  6: Officer First Name\n\t  7: Officer Last Name\n\t  8: Officer Race\n\t  9: Officer Gender\n\t 10: Current Rank Abbreviation\n\t 11: Current Rank\n\t 12: Current Command\n\t 13: Shield No\n\t 14: Complaint Id\n\t 15: Incident Date\n\t 16: CCRB Received Date\n\t 17: Close Date\n\t 18: Officer Rank Abbreviation At Incident\n\t 19: Officer Rank At Incident\n\t 20: Officer Command At Incident\n\t 21: Officer Days On Force At Incident\n\t 22: Borough Of Incident Occurrence\n\t 23: Precinct Of Incident Occurrence\n\t 24: Location Type Of Incident\n\t 25: Reason for Police Contact\n\t 26: Outcome Of Police Encounter\n\t 27: Victim Age At Incident\n\t 28: Victim Race\n\t 29: Victim Gender\n\t 30: FADO Type\n\t 31: Allegation\n\t 32: CCRB Allegation Disposition\n\t 33: Board Discipline Recommendation\n\t 34: Non-APU Penalty Report Date\n\t 35: Officer Is APU\n\t 36: APU CCRB Trial Recommended Penalty\n\t 37: APU Trial Commissioner Recommended Penalty\n\t 38: APU Plea Agreed Penalty\n\t 39: APU Case Status\n\t 40: APU Closing Date\n\t 41: NYPD Allegation Disposition\n\t 42: NYPD Officer Penalty\n\t 43: Reconsideration Requested\n\t 44: Reconsideration Request Withdrawn\n\t 45: Reconsideration Request Rejected\n\t 46: Reconsideration Occurred\n\t 47: Reconsideration Decision Pending\n\t \n[^3]: OfficersInvolvedInComplaints columns:\n\t1: As Of Date\n\t2: Officer Status\n\t3: Unique Officer Id\n\t4: Active Per Last Reported Status\n\t5: Last Reported Active Date\n\t6: Officer First Name\n\t7: Officer Last Name\n\t8: Officer Race\n\t9: Officer Gender\n\t10: Current Rank Abbreviation\n\t11: Current Rank\n\t12: Current Command\n\t13: Shield No\n\t14: Complaint Id\n\t15: Complaint Disposition\n\t16: Incident Date\n\t17: CCRB Recieved Date\n\t18: Close Date\n\t\n[^4]: I ran this in the CLI SQLite client to chop up the date string and re-write it in the way SQLite wants it: \n\t```sqlite\n\tupdate OfficerAllegationHistory\n\tset [Incident Date] = substr([Incident Date], -4) || '-' || \n\tsubstr('00' || ([Incident Date] + 0), -2, 2) || '-' ||\n\tsubstr('00' || (substr([Incident Date], instr([Incident Date], '/') + 1) + 0), -2, 2); \n\t```",
  "bodyHtml": "<h1>Finding Clusters of NYPD Officers In CCRB Complaint Data</h1>\n<h2>Why?</h2>\n<p>Complaints filed against police officers by the public are often the first- and only- warning signs that a cop might be on a course of escalating violence towards the public.</p>\n<p>In cases the deaths of George Floyd and Eric Garner the officers who killed them had a documented history of complaints filed against them by the public. Unfortunately nothing was done to disrupt their pattern of abuse, and both ended in the deaths of members of the public the officers had sworn to protect.</p>\n<p>[[toc]]</p>\n<h3>George Floyd</h3>\n<blockquote>\n<p>Chauvin, who was fired, has said through his attorney that his handling of Floyd’s arrest was a reasonable use of authorized force. But he was the subject of at least <strong>22 complaints</strong> or internal investigations during his more than 19 years at the department, <strong>only one of which resulted in discipline</strong>. These new interviews show not only that he may have used excessive force in the past, but that he had used startlingly similar techniques.\n<a href=\"https://www.mprnews.org/story/2021/02/05/that-could-have-been-me-the-people-derek-chauvin-choked-before-george-floyd\">https://www.mprnews.org/story/2021/02/05/that-could-have-been-me-the-people-derek-chauvin-choked-before-george-floyd</a></p>\n</blockquote>\n<p>The officer convicted of murdering George Floyd had at least 22 complaints against him. The officer who put Eric Garner in a chokehold and killed him had <a href=\"https://www.scribd.com/document/342591738/D-Pantaleo-Alleged-CCRB-File\">7 complaints</a> <a href=\"https://gothamist.com/news/newly-leaked-documents-suggests-cop-who-killed-eric-garner-had-history-of-misconduct\">filed against him</a>.</p>\n<h3>Eric Garner</h3>\n<blockquote>\n<p>Before he put Garner in the chokehold, the records show, he had <strong>seven disciplinary complaints and 14 individual allegations</strong> lodged against him. Four of those allegations were substantiated by an independent review board.\n<a href=\"https://archive.thinkprogress.org/daniel-pantaleo-records-75833e6168f3/\">https://archive.thinkprogress.org/daniel-pantaleo-records-75833e6168f3/</a></p>\n</blockquote>\n<p>Of the 14 individual allegations, 5 are for force: &quot;hit against inanimate object&quot;, &quot;physical force&quot;, and a single complaint in 2014 that would foreshadow the behavior that would eventually end the Officer's career: &quot;Force - Chokehold&quot;.</p>\n<p>I am documenting my analysis in detail for a few reasons:</p>\n<ul>\n<li>So that other people who may want to perform similar analysis for other Police Departments can understand and recreate my analysis</li>\n<li>So that every step is documented, and any mistake <a href=\"https://en.wikipedia.org/wiki/Linus%27s_law\">can be easily caught and fixed</a> by the infinite supply of people on the internet who are smarter than me</li>\n<li>To maybe inspire people to use computers to investigate the things in the world that are important to them, and share the tools I use to do that</li>\n</ul>\n<h3>Network visualization prior work / inspiration</h3>\n<p>You may have seen network analysis like this before.</p>\n<p><a href=\"https://disinformationindex.org/2021/03/anti-vaccine-networks-thrive-on-instagram-despite-recent-policy-shifts/\">Jacob Silver used it to look at the spread of anti-vax material</a>.</p>\n<p><a href=\"https://twitter.com/adico11\">Adi Cohen</a> has pioneered a method of <a href=\"https://help.crowdtangle.com/en/articles/4495952-network-mapping-with-gephi-and-crowdtangle\">combining Gephi with CrowdTangle</a> to analyze the network of groups and pages sharing links.</p>\n<h3>Provenance</h3>\n<p>The <a href=\"https://www.nyclu.org/en/campaigns/nypd-misconduct-database\">NYCLU</a> received this data from the CCRB as a result of a FOIL (Freedom of Information Law) request and released it on <a href=\"https://github.com/new-york-civil-liberties-union/NYPD-Misconduct-Complaint-Database-Updated\">their GitHub page</a>.</p>\n<h2>The Dataset</h2>\n<h3>Differences from data previously released by ProPublica</h3>\n<p>ProPublica released and covered <a href=\"https://www.propublica.org/article/nypd-civilian-complaint-review-board-editors-note\">similar data</a> in July of 2020.</p>\n<p>They chose to only publish data for &quot;active-duty officers who’ve had at least one allegation against them substantiated by the CCRB&quot;.</p>\n<p>The dataset we are working with today contains every complaint and officer, even those with no substantiated allegations.</p>\n<p>It also contains officers who were listed as witnesses on complaints, including complaints found as &quot;unsubstantiated&quot; or &quot;unfounded&quot; by the CCRB.</p>\n<p>This makes it a &quot;noisier&quot; dataset. In our case this can be an advantage since we are looking to visualize the network of officers.</p>\n<p>Being named with another officer on a complaint, even if that complaint is unfounded, is a signal that those officers interacted in a way that was noticed by the public. Being the subject of an unfounded complaint together might even cause officers to form a tighter relationship. Because of that, I will incorporate witness data into our analysis.</p>\n<h3>NYPD internal structure as it relates to our data</h3>\n<p>The NYPD is divided into coverage areas within the 5 boroughs known as precincts. When I lived in Brooklyn, I lived in the 81st Precinct which covers Bed-Stuy.</p>\n<p>The NYPD also has a number of units, like the Warrant Squad or Narcotics that span different precincts. An officer might report to a numbered precinct, but their command is Brooklyn Narcotics, and they are interacting with other officers in their unit more than the precinct they work out of. Our data reflects this.</p>\n<h2>Analysis</h2>\n<h3>Overview exploration / metadata</h3>\n<p>The source dataset is an 81.2MB excel file that I received as <code>FOIL2021-00167_Dataset.xlsx</code>. It has 3 tabs. The first has some general notes[^1] about the dataset.</p>\n<p>The first tab has the title of <strong>OfficerAllegationHistory</strong> and has 181,627 entries and 47[^2] columns.</p>\n<p>The second tab has the title of <strong>OfficersInvolvedInComplaints</strong> and has 239,608 entries and 18[^3] columns.</p>\n<h2>Analyzing our data with Datasette / SQLite</h2>\n<p>Once we <a href=\"https://pypi.org/project/csvs-to-sqlite/\">convert our CSV files</a> into SQLite <code>.db</code> files we can use <a href=\"https://github.com/simonw/datasette\">Datasette</a> to get a sense of the data and slice off pieces for further analysis.</p>\n<p>The first thing we might want to look at is the top commands that received complaints since 2010.</p>\n<pre><code class=\"hljs\">select [Officer Command At Incident], count([Officer Command At Incident]) from OfficerAllegationHistory \nwhere [Incident Date] BETWEEN &#x27;2010-01-01&#x27; AND &#x27;2010-12-31&#x27;\ngroup by [Officer Command At Incident] order by count([Officer Command At Incident]) DESC LIMIT 10</code></pre><ul>\n<li>075 PCT: 320</li>\n<li>046 PCT: 251</li>\n<li>047 PCT: 226</li>\n<li>120 PCT: 199</li>\n<li>BX IRT\t: 196</li>\n<li>NARCBBN: 178</li>\n<li>073 PCT: 176</li>\n<li>077 PCT: 173</li>\n<li>MN IRT: 171</li>\n<li>044 PCT: 168</li>\n</ul>\n<p>Or the top 10 commands whose complaints ended in penalties.</p>\n<pre><code class=\"hljs\">select [Officer Command At Incident], count([Officer Command At Incident]) from OfficerAllegationHistory \nwhere [Incident Date] BETWEEN &#x27;2010-01-01&#x27; AND &#x27;2021-12-31&#x27;AND [CCRB Allegation Disposition] = &#x27;Substantiated (Charges)&#x27;\ngroup by [Officer Command At Incident] order by count([Officer Command At Incident]) DESC LIMIT 10</code></pre><ul>\n<li>WARRSEC: 91</li>\n<li>PBBX\t: 84</li>\n<li>081 PCT: 71</li>\n<li>079 PCT: 70</li>\n<li>075 PCT: 68</li>\n<li>NARCBBN: 67</li>\n<li>046 PCT: 66</li>\n<li>034 PCT: 61</li>\n<li>NARCBBX: 56</li>\n<li>044 PCT: 54</li>\n</ul>\n<p>After using Datasette to get a sense for the shape of our dataset, we can use it to filter out a slice of the data to use to feed into our next tool and begin doing our network analysis.</p>\n<h3>Filtering out &quot;Exonerated&quot; and &quot;Unfounded&quot; complaints</h3>\n<p>To get our network closer to a representation of officers who are receiving complaints for misconduct we want to filter out any of the cases in which the officer was <strong>Exonerated</strong> or the CCRB's disposition was that it was <strong>Unfounded</strong>.</p>\n<p>So to get every complaint filed since 2010 that wasn't marked as <strong>exonerated</strong> or <strong>unfounded</strong> we'll write a query like</p>\n<pre><code class=\"hljs\">select * from OfficerAllegationHistory \nwhere ([Incident Date] BETWEEN &#x27;2010-01-01&#x27; AND &#x27;2021-12-31&#x27;) AND ([CCRB Allegation Disposition] IS NOT &#x27;Exonerated&#x27;\nAND [CCRB Allegation Disposition] IS NOT &#x27;Unfounded&#x27;)</code></pre><p>Which gives us a slightly more manageable <strong>65,401</strong> rows. We'll save these results off as a .csv for further analysis.</p>\n<p>I had to do some funky stuff[^4] to fix the dates in SQLite, but once I did that, it was easy to filter by the date column.</p>\n<p>We can also export new CSVs for all of the incidents since 2010 for a particular precinct:</p>\n<pre><code class=\"hljs\">select * from OfficerAllegationHistory \nwhere [Incident Date] BETWEEN &#x27;2010-01-01&#x27; AND &#x27;2021-12-31&#x27; AND [Officer Command At Incident] = &#x27;075 PCT&#x27;</code></pre><p>These precinct-specific slices are a bit smaller and more manageable for analysis in Observable.</p>\n<p>We'll also want to export another CSV with ONLY complaints that were substantiated</p>\n<pre><code class=\"hljs\">select * from OfficerAllegationHistory\nwhere ([Incident Date] BETWEEN &#x27;2010-01-01&#x27; AND &#x27;2021-12-31&#x27;) AND ([CCRB Allegation Disposition] IS &#x27;Substantiated (Charges)&#x27; OR [CCRB Allegation Disposition] IS &#x27;Substantiated (Command Discipline A)&#x27;\nOR [CCRB Allegation Disposition] IS &#x27;Substantiated (Command Discipline B)&#x27;</code></pre><h2>Analyzing our data with Observable</h2>\n<h2>Analyzing our data with Neo4J</h2>\n<p>I first encountered Neo4J when I was working with Ben Popken on an <a href=\"https://neo4j.com/blog/story-behind-russian-twitter-trolls/\">NBC News analysis of tweets tied to Senate Intelligence-identified Russian Twitter Bots</a> where Neo4J provided analysts who were crucial to understanding the shape of our data.</p>\n<p>It is an incredibly useful tool for generating and analyzing networks, and I was excited to have another dataset that would let me use its considerable power.</p>\n<h3>Importing our CSV with Cypher</h3>\n<p>To import our <code>.csv</code> into a network of node and relationships in Neo4J, we will use the <a href=\"https://neo4j.com/developer/cypher/\">Cypher</a> query language, which makes this process really easy and the code is relatively readable and easy to follow.</p>\n<p>Special thanks to <a href=\"https://twitter.com/mdavidallen\">David Allen</a> at Neo4J for his guidance in writing queries and designing these relationships.</p>\n<p>Basically we take the CSV files we exported from Datasette (when we filtered our Exonerated, Unfounded, and everything before 2010) and go through every row and push it into our network.</p>\n<h4>Creating officer nodes</h4>\n<p>First we tell Neo4J to use officer.id as a unique constraint (this makes things faster, I think?) and create a node for each officer from one CSV.</p>\n<pre><code class=\"hljs\">CREATE CONSTRAINT officerIdConstraint ON (officer:Officer) ASSERT officer.id IS UNIQUE</code></pre><p>Then I loop through every line of the .csv and create a new Officer node for every new officer I see. I use <code>MERGE</code> instead of <code>CREATE</code> to make sure I don't duplicate officer nodes.</p>\n<pre><code class=\"hljs\">LOAD CSV WITH HEADERS FROM &quot;http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv&quot; AS csvLine\nMERGE (officer:Officer {id: csvLine.`Unique Officer Id`, lastName: csvLine.`Officer Last Name`, firstName: csvLine.`Officer First Name`, OfficersInvolvedInComplaints: true})\nRETURN officer</code></pre><p>This creates <strong>29,915</strong> unique officer nodes.</p>\n<p>Then we bind more data into it from our other CSV</p>\n<pre><code class=\"hljs\">LOAD CSV WITH HEADERS FROM &quot;http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory.csv&quot; AS csvLine\nMERGE (officer:Officer {id: csvLine.`Unique Officer Id`, lastName: csvLine.`Officer Last Name`, firstName: csvLine.`Officer First Name`, shieldNo: csvLine.`Shield No`, currentRank: csvLine.`Current Rank`, currentCommand: csvLine.`Current Command`, OfficerAllegationHistory: true})\nRETURN officer</code></pre><p>Now we have <strong>113,265</strong> unique officer nodes.</p>\n<p>An officer node looks like this:</p>\n<pre><code class=\"hljs\">{\n  <span class=\"hljs-attr\">&quot;identity&quot;</span>: <span class=\"hljs-number\">00001</span>,\n  <span class=\"hljs-attr\">&quot;properties&quot;</span>: {\n\t\t<span class=\"hljs-attr\">&quot;currentRank&quot;</span>: <span class=\"hljs-string\">&quot;Police Officer&quot;</span>,\n\t\t<span class=\"hljs-attr\">&quot;currentCommand&quot;</span>: <span class=\"hljs-string\">&quot;81&quot;</span>,\n\t\t<span class=\"hljs-attr\">&quot;lastName&quot;</span>: <span class=\"hljs-string\">&quot;Smith&quot;</span>,\n\t\t<span class=\"hljs-attr\">&quot;firstName&quot;</span>: <span class=\"hljs-string\">&quot;John&quot;</span>,\n\t\t<span class=\"hljs-attr\">&quot;shieldNo&quot;</span>: <span class=\"hljs-string\">&quot;00001&quot;</span>,\n\t\t<span class=\"hljs-attr\">&quot;id&quot;</span>: <span class=\"hljs-string\">&quot;000001&quot;</span>,\n\t\t<span class=\"hljs-attr\">&quot;OfficerAllegationHistory&quot;</span>: <span class=\"hljs-literal\">true</span>\n  }\n}</code></pre><p>Finally, we need to add a boolean to denote if an officer has ever had a charge substantiated. We'll use this later to please some lawyers. You'll see.</p>\n<pre><code class=\"hljs\">LOAD CSV WITH HEADERS FROM &quot;http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-SUBSTANTIATED.csv&quot; AS csvLine\nMERGE (officer:Officer {id: csvLine.`Unique Officer Id`})\nSET officer.ccrbSubstantiatedBool = &quot;true&quot;\nRETURN officer</code></pre><p>Now we've marked <strong>4,768</strong> of New York's ~36,000 (13%) finest as having a substantiated complaint in the last 10 years.</p>\n<p>Let's NOT do the same thing for OfficersInvolved - because that file contains officers who were merely witnesses to substantiated complaints, and we don't want to accidentally label a witness to a substantiated case.</p>\n<h3>Creating officer labels</h3>\n<p>Now we need to set labels for our nodes depending on whether they have ever had a complaint substantiated. We don't want to label nodes with names for any officers who may have complaints but have never had any substantiated. I have been told that lawyers think this is a good idea.</p>\n<p>First we set every officer label to their unique ID</p>\n<pre><code class=\"hljs\">MATCH (o:Officer)\nSET o.label = o.id</code></pre><p>Then we look for officers with substantiated complaints and set their label to their full name.</p>\n<pre><code class=\"hljs\">MATCH (o:Officer {ccrbSubstantiatedBool: &quot;true&quot;})\nSET o.label = COALESCE(o.firstName ,&quot;&quot;) + &#x27; &#x27; + COALESCE(o.lastName ,&quot;&quot;)</code></pre><p>Now we have our officers created, we need to create our incidents.</p>\n<h4>MAYBE, POTENTIALLY</h4>\n<p>In order to include dates in our network, we might need to make a dummy date field for our officers. Only incidents have dates in our source data, but to export our dates to Gephi, all nodes need to have the field.</p>\n<pre><code class=\"hljs\">MATCH (o:Officer )\nSET o.date = &quot;2021-12-31&quot;</code></pre><p>Ideally this would be the date the officer was hired, but that is extra work for unclear reward, though you could probably do some interesting analysis incorporating seniority or analyzing the network effects of complaint-prone cops working with rookies and potentially influencing their behavior.</p>\n<h4>Creating incident nodes</h4>\n<p>We are going to continue to use our CSV which <strong>filtered out</strong> incidents <strong>before 2010</strong> or that were <strong>unfounded or exonerated</strong>.</p>\n<p>First we tell Neo4J that we have unique incident IDs</p>\n<pre><code class=\"hljs\">CREATE CONSTRAINT incidentIdConstraint ON (incident:Incident) ASSERT incident.id IS UNIQUE</code></pre><p>Then we create an incident for every row we see in OfficerAllegationHistory. We'll make note of the precinct the incident occurred in, what the specific allegation was, and what date the incident occurred.</p>\n<pre><code class=\"hljs\">LOAD CSV WITH HEADERS FROM &quot;http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv&quot; AS csvLine\nMERGE (incident:Incident {id: csvLine.`Complaint Id`})\nSET incident.incidentPct = COALESCE(csvLine.`Precinct Of Incident Occurrence`,&quot;N/A&quot;)\nSET incident.ccrbDisposition = csvLine.`CCRB Allegation Disposition`\nSET incident.allegation = csvLine.`Allegation`\nset incident.date = csvLine.`Incident Date`\nRETURN incident</code></pre><p>Now let's do the same for <strong>OfficersInvolvedInComplaints</strong>.</p>\n<pre><code class=\"hljs\">LOAD CSV WITH HEADERS FROM &quot;http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv&quot; AS csvLine\nMERGE (incident:Incident {id: csvLine.`Complaint Id`})\nSET incident.ccrbDisposition = csvLine.`Complaint Disposition`\nRETURN incident</code></pre><p>Now let's create labels for our incidents, which is going to be the allegation.</p>\n<pre><code class=\"hljs\">MATCH (i:Incident)\nSET i.label = i.allegation</code></pre><p>Now that we have our <strong>Incidents</strong> and our <strong>Officers</strong> we need to create our relationships between them.</p>\n<h3>Creating relationships between incidents and officers</h3>\n<p>Now for the fun part.</p>\n<p>We are going to create a new relationship called <code>INVOLVED_IN</code>, and officers can be <code>INVOLVED_IN</code> one or many incidents. Incidents may have one or many officers that were <code>INVOLVED_IN</code> it, either as witness or subject officers.</p>\n<p>First we create our relationships from <strong>OfficersInvolved</strong>:</p>\n<pre><code class=\"hljs\">LOAD CSV WITH HEADERS FROM &quot;http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficersInvolvedInComplaints_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv&quot; AS csvLine\nMATCH (officer:Officer {id: csvLine.`Unique Officer Id`}) with csvLine, officer\nMATCH (incident:Incident {id: csvLine.`Complaint Id`}) with csvLine, officer, incident\nCREATE (officer)-[:INVOLVED_IN {status: csvLine.`Officer Status`}]-&gt;(incident)</code></pre><p>Which creates <strong>94,323</strong> relationships.</p>\n<p>Then from <strong>OfficerAllegationHistory</strong>:</p>\n<pre><code class=\"hljs\">LOAD CSV WITH HEADERS FROM &quot;http://localhost:11001/project-185bb75c-b944-451a-9c0f-aeba860ae68a/OfficerAllegationHistory_FILTERED-SINCE2010-NOT-UNFOUNDED-EXONERATED.csv&quot; AS csvLine\nMATCH (officer:Officer {id: csvLine.`Unique Officer Id`}) with csvLine, officer\nMATCH (incident:Incident {id: csvLine.`Complaint Id`}) with csvLine, officer, incident\nCREATE (officer)-[:INVOLVED_IN {allegation: csvLine.`Allegation`, type: csvLine.`FADO Type`}]-&gt;(incident)</code></pre><p>Now we have <strong>159,671</strong> relationships. Sick.</p>\n<p>Next we can flatten out our graph a little bit and remove incidents if we want.</p>\n<p>We will create a new type of relationship that only occurs between two officers called <code>CO_OCCURANCE</code> - we will only make one of these between each officer, but the weight of that link will be decided by how many complaints those officers appear together on.</p>\n<p>So officers who appear on 3 complaints together have a <code>CO_OCCURANCE</code> relationship with a weight of 3. This allows us to do some weighted degree analysis when we are making our layout, deciding how large to make nodes, and when we are detecting communities.</p>\n<pre><code class=\"hljs\">MATCH (o1:Officer)-[:INVOLVED_IN]-&gt;(i:Incident)&lt;-[:INVOLVED_IN]-(o2:Officer) WHERE id(o1)&lt;id(o2) with o1, o2, count(i) as weightCount CREATE (o1)-[:CO_OCCURANCE { weight: weightCount }]-&gt;(o2)</code></pre><h3>Eigenvector analysis on our network</h3>\n<p>Let's run a standard centrality analysis algorithm called <a href=\"https://neo4j.com/docs/graph-data-science/current/algorithms/eigenvector-centrality/\">&quot;Eigenvector Centrality&quot;</a></p>\n<pre><code>CALL gds.alpha.eigenvector.write({\n  nodeProjection: 'Officer',\n  relationshipProjection: 'CO_OCCURANCE',\n  relationshipProperties: 'weight',\n  relationshipWeightProperty: 'weight',\n  writeProperty: 'eigenvector'\n})\nYIELD nodes, iterations, dampingFactor, writeProperty\n</code></pre>\n<p>Now every Officer node has an <code>eigenvector</code> value that represents its centrality across our entire NYPD-wide network. The larger the value, the more central that node is.</p>\n<p>We're also going to find the <a href=\"https://neo4j.com/docs/graph-data-science/current/algorithms/modularity-optimization/\">modularity</a> for our network using Neo4J. This will help us color our nodes by their &quot;community&quot; as defined by this network.</p>\n<pre><code class=\"hljs\">CALL gds.graph.create.cypher(\n    &#x27;nypdwide&#x27;,\n\t  &#x27;MATCH (n:Officer) RETURN id(n) AS id&#x27;,\n\t\t&#x27;MATCH (a:Officer)-[l:CO_OCCURANCE]-&gt;(b:Officer) RETURN id(a) AS source, id(b) AS target, l.weight AS weight&#x27;\n)\nYIELD graphName, nodeCount, relationshipCount, createMillis;</code></pre><pre><code class=\"hljs\">CALL gds.beta.modularityOptimization.mutate(&#x27;nypdwide&#x27;, { relationshipWeightProperty: &#x27;weight&#x27;, mutateProperty: &#x27;community&#x27; })\nYIELD nodes, communityCount, ranIterations, didConverge</code></pre><p>The communities that Gephi detects often mirror real-world precincts. As one might expect, officers appear on complaints with other officers in their precinct because they are working together most often.</p>\n<p>I like that the algorithm detects communities that resemble precincts, and it actually gives me confidence that the community detection is working.</p>\n<h2>Analyzing our data with Gephi</h2>\n<p>Neo4J is cool for processing and analyzing tons of data, but I want to draw thousands of circles and lines now and start untangling the hairball of our network.</p>\n<p>I am going to use Gephi, which I have a love-hate relationship with, but is unrivaled when it comes to network visualization. Plus, I already know how to use it.</p>\n<p>We are going to <a href=\"https://neo4j.com/labs/apoc/4.1/export/gephi/\">stream our data from Neo4J to Gephi</a> in order to leverage Neo4J's power to handle huge amounts of data (way more than Gephi) but still get to use Gephi's layout algorithms and analysis techniques.</p>\n<h3>Flattened co-occurance network</h3>\n<p>To get our flattened network, which removed incident nodes:</p>\n<pre><code class=\"hljs\">MATCH path=(o1:Officer)-[r:CO_OCCURANCE]-&gt;(o2:Officer) WITH o1, path limit 100000  with o1, collect(path) as paths call apoc.gephi.add(null,&#x27;workspace1&#x27;, paths, &#x27;weight&#x27;, [&#x27;weight&#x27;, &#x27;id&#x27;, &#x27;eigenvector&#x27;, &#x27;firstName&#x27;, &#x27;lastName&#x27;, &#x27;label&#x27;, &#x27;date&#x27;, &#x27;currentCommand&#x27;]) yield nodes, relationships, time return nodes, relationships, time ORDER  BY o1.eigenvector DESC</code></pre><p>This streams 100,000 edges and 25,064 nodes into Gephi.</p>\n<p>We'll run the Force Atlas 2 layout algorithm in Gephi to have the nodes arrange themselves into some sort of sense.</p>\n<h3>Precinct-specific networks including incidents</h3>\n<p>Let's put it all together and stream all the officers from a single precinct using only incidents since 2010.</p>\n<pre><code class=\"hljs\">MATCH path=(o1:Officer)-[:INVOLVED_IN]-&gt;(i:Incident {incidentPct: &quot;75&quot;})&lt;-[:INVOLVED_IN]-(o2:Officer)\nwhere i.date IS NOT NULL and apoc.date.parse(i.date, &quot;ms&quot;, &#x27;YYYY-mm-dd&#x27;) &gt; 1262304000000\n WITH o1, path, i limit 100000  with o1, i, collect(path) as paths call apoc.gephi.add(null,&#x27;workspace1&#x27;, paths, &#x27;weight&#x27;, [&#x27;weight&#x27;, &#x27;id&#x27;, &#x27;eigenvector&#x27;, &#x27;firstName&#x27;, &#x27;lastName&#x27;, &#x27;date&#x27;]) yield nodes, relationships, time return nodes, relationships, time ORDER  BY o1.eigenvector DESC</code></pre><h2>Visualization</h2>\n<h2>Potential Next Steps</h2>\n<h3>Explorable NYPD-wide network</h3>\n<h3>Looking at protest complaints</h3>\n<h3>Looking at veterans influencing rookies</h3>\n<h3>Looking at the effects of NYPD discipline</h3>\n<h3>Officer career-specific visualization</h3>\n<h3>Analysis of length/outcomes of CCRB investigations</h3>\n<h3>Geographic analysis</h3>\n<h2>Hire me to do work like this</h2>\n<p>I do freelance data exploration and visualization for clients who aren't evil. I'd love to work like this for you, just get in touch at <a href=\"mailto:ejfox@ejfox.com\">ejfox@ejfox.com</a></p>\n<p>[^1]: The notes say, basically: these are complaints received in or after the year 2000. Cases that are mediated or were attempted to be mediated are excluded.</p>\n<p>[^2]: OfficerAllegationHistory columns:\n1: As Of Date\n2: Allegation Record Identity\n3: Unique Officer Id\n4: Active Per Last Reported Status\n5: Last Reported Active Date\n6: Officer First Name\n7: Officer Last Name\n8: Officer Race\n9: Officer Gender\n10: Current Rank Abbreviation\n11: Current Rank\n12: Current Command\n13: Shield No\n14: Complaint Id\n15: Incident Date\n16: CCRB Received Date\n17: Close Date\n18: Officer Rank Abbreviation At Incident\n19: Officer Rank At Incident\n20: Officer Command At Incident\n21: Officer Days On Force At Incident\n22: Borough Of Incident Occurrence\n23: Precinct Of Incident Occurrence\n24: Location Type Of Incident\n25: Reason for Police Contact\n26: Outcome Of Police Encounter\n27: Victim Age At Incident\n28: Victim Race\n29: Victim Gender\n30: FADO Type\n31: Allegation\n32: CCRB Allegation Disposition\n33: Board Discipline Recommendation\n34: Non-APU Penalty Report Date\n35: Officer Is APU\n36: APU CCRB Trial Recommended Penalty\n37: APU Trial Commissioner Recommended Penalty\n38: APU Plea Agreed Penalty\n39: APU Case Status\n40: APU Closing Date\n41: NYPD Allegation Disposition\n42: NYPD Officer Penalty\n43: Reconsideration Requested\n44: Reconsideration Request Withdrawn\n45: Reconsideration Request Rejected\n46: Reconsideration Occurred\n47: Reconsideration Decision Pending</p>\n<p>[^3]: OfficersInvolvedInComplaints columns:\n1: As Of Date\n2: Officer Status\n3: Unique Officer Id\n4: Active Per Last Reported Status\n5: Last Reported Active Date\n6: Officer First Name\n7: Officer Last Name\n8: Officer Race\n9: Officer Gender\n10: Current Rank Abbreviation\n11: Current Rank\n12: Current Command\n13: Shield No\n14: Complaint Id\n15: Complaint Disposition\n16: Incident Date\n17: CCRB Recieved Date\n18: Close Date</p>\n<p>[^4]: I ran this in the CLI SQLite client to chop up the date string and re-write it in the way SQLite wants it:\n<code>sqlite \tupdate OfficerAllegationHistory \tset [Incident Date] = substr([Incident Date], -4) || '-' ||  \tsubstr('00' || ([Incident Date] + 0), -2, 2) || '-' || \tsubstr('00' || (substr([Incident Date], instr([Incident Date], '/') + 1) + 0), -2, 2);  \t</code></p>\n",
  "title": "Finding Clusters of NYPD Officers In CCRB Complaint Data",
  "dir": "content/blog/posts",
  "base": "nypd-ccrb-complaint-clusters.json",
  "ext": ".json",
  "sourceBase": "nypd-ccrb-complaint-clusters.md",
  "sourceExt": ".md"
}